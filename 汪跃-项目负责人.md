# 汪跃｜项目负责人

![头像](https://www.bjzgca.edu.cn/adminapi/public/assets/avatar/Mask%20group-32.png)


- 邮箱：yuewang@bza.edu.cn
- 学院主页：https://www.bjzgca.edu.cn/teacher/4b6e5ed12ce4492da61c808b9d48a44a

研究聚焦强化学习算法的**有效性**与**效率**，以大模型应用为牵引推进**大规模强化学习算法研究与工程实践**；同时在科学智能的物理系统建模与神经 PDE 方法方面持续开展工作。

---

## 人物经历

- **2011–2015**：北京交通大学｜信息与计算科学｜本科
- **2015–2020**：北京交通大学｜概率论与数理统计｜博士（师从马志明院士）
- **2020–2022**：微软亚洲研究院｜研究员
- **2022–2025**：微软亚洲研究院｜科学智能中心｜高级研究员
- **2025–至今**：北京中关村学院｜研究员、助理教授
- **2025-至今**：北京新烛时代科技有限公司 | 联合创始人、CTO

---

## 研究方向与代表工作

### 方向 1｜强化学习基础理论与算法创新

围绕强化学习的**收敛性、泛化性与迁移性**等关键问题，探索高效策略优化与价值评估方法，为更大规模训练与更复杂任务提供理论与算法支撑。

- 代表论文：[12]、[11]、[10]、[8]

---

### 方向 2｜大模型应用驱动的大规模强化学习研究与实践

面向大语言模型的推理与对齐训练，研究可规模化的策略优化范式与训练流程，强调**统一框架、理论解释与工程可复现**，并以真实训练/对齐场景推动算法设计与落地。本项目组以该方向为主线开展研究与工程实践。

- 公开报告：RLChina 2025 Workshop《从PPO到DPO：一个统一策略优化框架及其在大型语言模型训练中的应用》
- 相关论文：[8]、[6]

---

### 方向 3｜科学智能：物理系统建模与神经 PDE 方法

聚焦物理系统的建模与求解，研究在**部分观测、物理约束、以及高效数值/学习结合**等条件下的神经 PDE 求解器与数据/物理协同建模方法，并在流体、极端天气预测等任务中开展验证。  
注：可控核聚变方向由其另一个团队/课题组推进；本项目组以“大模型应用驱动下的大规模强化学习算法研究与实践”为主线开展研究。

- 代表论文：[1]、[2]、[4]、[7]、[9]、[3]、[5]

---

## 产业化与公开交流

- 学术报告：RLChina 2025 Workshop《从PPO到DPO：一个统一策略优化框架及其在大型语言模型训练中的应用》  
  http://rlchina.org/rlchina_2025/Workshop.html
- 媒体与公开文章：
  - AI加速“人造太阳”商业化丨新烛时代CTO汪跃应《文汇报》邀请分享前瞻观点：https://mp.weixin.qq.com/s/EFaUy7P_FpMMU_ONmIX0kA
  - 汪跃的跨界三重奏：从科研深耕到育人、创业：https://mp.weixin.qq.com/s/c3HQSi9OiVPHPhcaMlG3PQ
  - 新烛时代相关公开文章（补充阅读）：
    - https://mp.weixin.qq.com/s/wzhpcf4S22HrkZEGgKq2ww
    - https://mp.weixin.qq.com/s/HCP4LRBnBLlCefy6aoOLOQ
    - https://mp.weixin.qq.com/s/ks4uK45XXfyhsCaqaheRFQ

---

## 代表性学术论文

注：编号用于本文档内部引用。

[1] Haodong Feng, Yue Wang, Dixia Fan. “How to Re-enable PDE Loss for Physical Systems Modeling Under Partial Observation.” AAAI 2025.  
[2] “Monte Carlo Neural PDE Solver for Learning PDEs via Probabilistic Representation.” TPAMI 2025.  
[3] Nian Ran, Peng Xiao, Yue Wang, Wesley Shi, Jianxin Lin, Qi Meng, Richard Allmendinger. “HR-Extreme: A High-Resolution Dataset for Extreme Weather Forecasting.” ICLR 2025.  
[4] Peiyan Hu, Yue Wang, and Zhi-Ming Ma. “Better neural PDE solvers through data-free mesh movers.” ICLR 2024.  
[5] Haodong Feng, Yue Wang, Hui Xiang, Zhiyang Jin, and Dixia Fan. “How to Control Hydrodynamic Force on Fluidic Pinball via Deep Reinforcement Learning.” Physics of Fluids, 35(4), 2023.  
[6] Jinhua Zhu, Yue Wang, Lijun Wu, Tao Qin, Wengang Zhou, Tie-Yan Liu, and Houqiang Li. “Making Better Decision by Directly Planning in Continuous Control.” ICLR 2023.  
[7] Xinquan Huang, Wenlei Shi, Qi Meng, Yue Wang, Xiaotian Gao, Jia Zhang, and Tie-Yan Liu. “NeuralStagger: Accelerating Physics-constrained Neural PDE Solver with Spatial-temporal Decomposition.” ICML 2023.  
[8] Chongchong Li, Yue Wang, Wei Chen, Yuting Liu, Zhi-Ming Ma, and Tie-Yan Liu. “Gradient information matters in policy optimization by back-propagating through model.” ICLR 2022.  
[9] Rui Zhang, Peiyan Hu, Qi Meng, Yue Wang, Rongchan Zhu, Bingguang Chen, Zhi-Ming Ma, and Tie-Yan Liu. “DRVN (deep random vortex network): A New Physics-Informed Machine Learning Method for Simulating and Inferring Incompressible Fluid Flows.” Physics of Fluids, 34(10), 2022.  
[10] Yue Wang, Yuting Liu, Wei Chen, Zhi-Ming Ma, and Tie-Yan Liu. “Target transfer Q-learning and its convergence analysis.” Neurocomputing 392 (2020): 11–22.  
[11] Yue Wang, Wei Chen, Yuting Liu, Zhi-Ming Ma, and Tie-Yan Liu. “Finite sample analysis of the GTD policy evaluation algorithms in Markov setting.” NeurIPS 2017.  
[12] Qi Meng, Yue Wang, Wei Chen, Taifeng Wang, Zhi-Ming Ma and Tie-Yan Liu. “Generalization Error Bounds for Optimization Algorithms via Stability.” AAAI 2017.
