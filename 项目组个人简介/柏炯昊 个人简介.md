# 柏炯昊 个人简介

![微信图片_20241117212421.jpeg](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1X3lE5jjbxA4mlJb/img/a9569924-701d-4573-9870-4936e57ed786.jpeg)

**柏炯昊**

大模型强化学习

教育背景：

2020-2024 浙江大学 人工智能 学士学位  
2024-2029（预计）浙江大学 计算机科学与技术 博士  
2024-2029（预计）北京中关村学院  大模型应用驱动下的大规模强化学习算法研究与实践项目组 博士

研究方向：

大模型强化学习的后训练相关技术

研究成果：

1.  【ICML submission】Arbitrary Entropy Policy Optimization Breaks The Exploration Bottleneck of Reinforcement Learning 
    
    *   Chen Wang\*, Zhaochun Li\*, **Jionghao Bai\***, Ge Lan, Shisheng Cui, Zhou Zhao, Yue Wang
        
    *   提出了LLM强化学习后训练中的任意控熵算法AEPO。使用完整的策略梯度作为正则代替传统的熵正则，确保正则项在优化过程中永远不会处于主导地位。
        
2.  【ICML submission】Distribution-Centric Policy Optimization Dominates Exploration-Exploitation Trade-off
    
    *   Zhaochun Li\*, Chen Wang\*, **Bai Jionghao\***, Guanting Dong, Shisheng Cui, Ge Lan, Zhou Zhao, Yue Wang
        
    *   证明了在LLM强化学习后训练中，相较于单个样本，由样本总体所形成的期望梯度占主导地位，并依此提出了完全on-policy的熵控制算法DCPO。