# 邓贺烜-个人简介

个人主页：[https://hexuandeng.github.io/](https://hexuandeng.github.io/)

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/pLdn55X7864ppno8/img/826dc821-1bab-451e-a81f-9f25cb27a95b.png)

## 🎓 教育背景

### 南开大学，天津（2018 年 09 月 -- 2022 年 07 月）

_工学学士_ 人工智能学院，智能科学与技术专业，特色班；平均学分绩点 3.79/4，学院排名 8/129

### 哈尔滨工业大学，深圳，广东（2022 年 09 月 -- 2024 年 07 月）

_工学硕士_ 保研至计算机科学与技术学院，计算与智能研究院；导师：张民，刘学博，张梅山

### 哈尔滨工业大学，深圳，广东（2024 年 09 月 -- 2027 年 06 月（预计））

_工学博士在读_ 硕博连读至计算机科学与技术学院，计算与智能研究院；导师：张民，刘学博

### 北京中关村学院，北京（2024 年 09 月 -- 2024 年 06 月（预计））

_工学博士在读_ 北京中关村学院联培，参与强化学习算法研究与实践项目；导师：汪跃

### 获2025年研究生国家奖学金

## 💼 实习经历

### 京东集团 - 京东科技 - 探索研究院，北京（2021年11月 -- 2022年05月）

**科研实习**：算法工程师岗，企业导师：丁亮，陶大程

*   调研同声传译系统方向，提出单语数据利用策略，发表AAAI 2023论文一篇；
    

### 腾讯科技（深圳）- TEG技术工程事业群 - AI Lab，深圳（2023年07月 -- 2024年12月）

**科研实习**：交互翻译组实习生，企业导师：焦文祥，涂兆鹏

*   提出检测大模型新词能力的基准测试构建方法，发表NeurIPS 2024 D&B论文一篇；
    
*   阅读大模型训练与剪枝的代码，添加训练数据及损失函数加权策略，发表ACL 2025 Main论文一篇。
    

## ⚗️ 研究工作

聚焦**大语言模型**最新研究方向，以**数据合成与利用**为切入点，关注前人较少关注的问题或切入角度，聚焦于对**问题的完善定义**以及**简单有效的解决方案**。最新关注方向为在线强化学习，后续研究计划围绕Agentic RL。

### Improving Simultaneous Machine Translation with Monolingual Data.（AAAI 2023）

Author: **Hexuan Deng**, Liang Ding, Xuebo Liu, Meishan Zhang, Dacheng Tao, Min Zhang.

*   证明常用的整句机翻数据训练**同声传译模型**的局限性，以及蒸馏单语数据相比整句机翻数据更适合同传；
    
*   借鉴人类译员的策略，提出更优的单语**数据选择**方法，有效降低幻觉现象。
    

### `**NewTerm**`: Benchmarking Real-Time New Terms for Large Language Models with Annual Updates.（NeurIPS 2024 D&B）

Author: **Hexuan Deng**, Wenxiang Jiao, Xuebo Liu, Min Zhang, Zhaopeng Tu.

*   新知识、**新词的涌现**限制了大模型的**实时性**，但新词的测试较难，且静态构建方法不适用于实时知识测试；
    
*   较早的利用**数据合成**pipeline构建benchmark，实现低成本实时更新，且保持准确的系统级评价；
    
*   使用上述方案构建新词的NLU测试数据，实现新词的可靠评测，并依此广泛揭示现有模型的缺陷。
    

### `**NewTerm++**`: Evaluating and Improving Large Language Models on Real-Time New Terms.（TASLP Submission）

Author: **Hexuan Deng**, Wenxiang Jiao, Chunhao Tian, Xuebo Liu, Min Zhang, Zhaopeng Tu.

*   证明传统的知识编辑以及RAG方法**无法较好的处理新词**这一问题；
    
*   提出**数据合成**方法，指出上下文的重要性并构建示例句子，仅使用LoRA微调便全面超越上述baseline。
    

### `**DRPruning**`: Efficient Large Language Model Pruning through Distributionally Robust Optimization.（ACL 2025 Main）

Author: **Hexuan Deng**, Wenxiang Jiao, Xuebo Liu, Min Zhang, Zhaopeng Tu.

*   **结构化剪枝**方法常导致不同领域**性能不均衡退化**，影响下游任务表现并引入偏差；
    
*   引入并改进分布鲁棒剪枝方法，动态调整训练过程中的训练预期，提升训练过程中的**数据利用效率**。
    

### `**REA-RL**`: Reflection-Aware Online Reinforcement Learning for Efficient Large Reasoning Models.（ICLR 2026）

Author: **Hexuan Deng**, Wenxiang Jiao, Xuebo Liu, Jun Rao, Min Zhang.

*   为了解决**过度思考**，长度奖励或在组内计算，易导致反思能力崩溃；或在固定长度下计算，忽视问题难度变化；
    
*   定义“必要思考路径”，执行**在线数据合成**，以对非必要部分针对性惩罚，指导模型收敛方向，避免丧失反思；
    
*   添加反思奖励，避免模型以丧失反思为代价降低路径长度，往往显著降低性能；
    
*   不降低性能的前提下平均缩短响应35%。方法能在**难题上保持反思频率**、在**易题上适度减少反思**。
    

### `**CoCoReviewBench**`: A Completeness- and Correctness-Oriented Benchmark for AI Reviewers.（ICML 2026 Submission）

Author: **Hexuan Deng**\*, Xiaopeng Ke\*, Yichen Li\*, Ruina Hu\*, Dehao Huang, Derek F. Wong, Yue Wang, Xuebo Liu, Min Zhang.

*   **AI Reviewer评价难**。或仅基于LLM评价，存在bias，或评价与人类意见相似性，而非正确性；
    
*   揭示人类意见的**不全面性**和**冲突性**，揭示潜在的错误，使得其不适合作为gold reference；
    
*   使用**基于Agent的数据合成**，构建类别级评价避免不全面性，并使用同行讨论作为人类标注，删除错误意见；
    
*   发现现有方案在正确性和深入性上仍需改善，尤其是论文质量外的类别，且推理模型是更好的AI Reviewer。
    

### `**AQuilt**`: Weaving Logic and Self-Inspection into Low-Cost, High-Relevance Data Synthesis for Specialist LLMs.（EMNLP 2025 Main）

Author: Xiaopeng Ke, **Hexuan Deng**, Xuebo Liu, Jun Rao, Zhenxi Song, Jun Yu, Min Zhang.   指导柯潇鹏，2024级哈工深硕士，使用**数据合成**方法**转无标注数据为有标注数据**，提升训练效率并解决专有领域数据缺乏的问题。另与其合作完成上述ICML投稿论文一篇，潇鹏为共一二作。

### Stop Rewarding Hallucinated Steps: Faithfulness-Aware Step-Level Reinforcement Learning for Small Reasoning Models.（ICML 2026 Submission）

Author: Shuo Nie\*, **Hexuan Deng**\*, Chao Wang, Ruiyu Fang, Xuebo Liu, Shuangyong Song, Yu Li, Min Zhang, Xuelong Li.   指导聂硕，2025级哈工深硕士，发现**小推理模型的幻觉**更严重，并设计显式和隐式**步骤奖励**以缓解。